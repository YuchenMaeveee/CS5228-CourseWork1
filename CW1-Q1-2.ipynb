{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CS5228-KDDM, 2025/26-2, Coursework 1\n",
    "\n",
    "### Introduction\n",
    "Following the data cleaning phase, the dataset (result1-1.csv) is now assumed to be free of missing values and dirty records. However, to apply mathematical models and distance-based machine learning algorithms, the data must be transformed into a suitable numerical format. Q1-2 focuses on these essential data transformation steps.\n",
    "\n",
    "The primary objectives of this section are twofold:\n",
    "\n",
    "* Categorical Encoding: Many machine learning algorithms cannot process text data directly. We will convert specific categorical attributes—namely Workclass (Column B), Education (Column D), and Sex (Column J)—into numerical representations using unique integer labels (pseudo encoding). The intermediate result will be saved as result1-2.csv.\n",
    "\n",
    "\n",
    "* Data Normalization: As observed in Task 1.1, the Capital Gain (Column K) and Capital Loss (Column L) attributes exhibit extreme sparsity and large numerical ranges. To prevent these large values from dominating distance calculations, we will apply a Z-transform (Standardization) to scale these features so they have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "The final, fully preprocessed dataset will be saved as result1-3.csv, ready for subsequent clustering analysis."
   ],
   "id": "d97c1950d22940c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Student Name: MA YUCHEN\n",
    "#### Student Number: A0327384X"
   ],
   "id": "68cfbb8600738feb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CW1, Part 1: Data Preprocessing using Python (2+2=4 marks)",
   "id": "6befd3ca8d70ce5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### CW1-1-2: Data Transformation (2 marks) \n",
    "#### Datasets: result1-1.csv \n",
    "This dataset is assumed to be clean and without any missing or dirty values. "
   ],
   "id": "f13b1ac2620b54b9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-13T16:03:02.030011Z",
     "start_time": "2026-02-13T16:03:01.850447Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:03:03.158535Z",
     "start_time": "2026-02-13T16:03:03.152373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_categorical_columns(df):\n",
    "    # B: workclass\n",
    "    # D: education\n",
    "    # J: sex\n",
    "    target_cols = ['workclass', 'education', 'sex']\n",
    "    \n",
    "\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    for col in target_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        \n",
    "\n",
    "    # Show the first 15 records\n",
    "    print(\"\\nThe first 15 records:\")\n",
    "    print(df.head(15))\n",
    "    \n",
    "    # Save Result\n",
    "    output_file = 'result1-2.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Save the Data to {output_file}\")\n",
    "    \n",
    "    return df"
   ],
   "id": "60ee1f1654c85c09",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:03:05.008426Z",
     "start_time": "2026-02-13T16:03:05.001421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_capital_columns(df):\n",
    "\n",
    "    # K: capital-gain\n",
    "    # L: capital-loss\n",
    "    norm_cols = ['capital-gain', 'capital-loss']\n",
    "    \n",
    "    # 1. Print Mean, Std (Before Normalization)\n",
    "    print(\"Before Normalization:\")\n",
    "    for col in norm_cols:\n",
    "        print(f\"  {col}: Mean = {df[col].mean():.4f}, Std = {df[col].std():.4f}\")\n",
    "        \n",
    "    # 2. Z-transform: z = (x - mean) / std\n",
    "    for col in norm_cols:\n",
    "        mean_val = df[col].mean()\n",
    "        std_val = df[col].std(ddof=0) \n",
    "        df[col] = (df[col] - mean_val) / std_val\n",
    "    \n",
    "    # 3. Print Mean, Std (After Normalization) \n",
    "    # Check Mean ≈ 0, Std ≈ 1\n",
    "    print(\"\\nAfter Normalization:\")\n",
    "    for col in norm_cols:\n",
    "        print(f\"  {col}: Mean = {df[col].mean():.4f}, Std = {df[col].std():.4f}\")\n",
    "        \n",
    "    # 4. Show the last 15 records\n",
    "    print(\"\\nThe last 15 records of Target Columns):\")\n",
    "    print(df.tail(15))\n",
    "    \n",
    "    # Save Result\n",
    "    output_file = 'result1-3.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Save the Data to {output_file}\")\n",
    "    \n",
    "    return df"
   ],
   "id": "d91f853865ac4989",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:03:08.082411Z",
     "start_time": "2026-02-13T16:03:07.773263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('result1-1.csv')\n",
    "    df_encoded = encode_categorical_columns(df)\n",
    "    df_normalized = normalize_capital_columns(df_encoded)"
   ],
   "id": "378e5e12af77bd06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The first 15 records:\n",
      "    age  workclass  fnlwgt  education  education-num         marital-status  \\\n",
      "0    39          5   77516          9             13          Never-married   \n",
      "1    50          4   83311          9             13     Married-civ-spouse   \n",
      "2    38          2  215646         11              9               Divorced   \n",
      "3    53          2  234721          1              7     Married-civ-spouse   \n",
      "4    28          2  338409          9             13     Married-civ-spouse   \n",
      "5    37          2  284582         12             14     Married-civ-spouse   \n",
      "6    49          2  160187          6              5  Married-spouse-absent   \n",
      "7    52          4  209642         11              9     Married-civ-spouse   \n",
      "8    31          2   45781         12             14          Never-married   \n",
      "9    42          2  159449          9             13     Married-civ-spouse   \n",
      "10   37          2  280464         15             10     Married-civ-spouse   \n",
      "11   30          5  141297          9             13     Married-civ-spouse   \n",
      "12   23          2  122272          9             13          Never-married   \n",
      "13   32          2  205019          7             12          Never-married   \n",
      "14   34          2  245487          5              4     Married-civ-spouse   \n",
      "\n",
      "           occupation   relationship                race  sex  capital-gain  \\\n",
      "0        Adm-clerical  Not-in-family               White    1          2174   \n",
      "1     Exec-managerial        Husband               White    1             0   \n",
      "2   Handlers-cleaners  Not-in-family               White    1             0   \n",
      "3   Handlers-cleaners        Husband               Black    1             0   \n",
      "4      Prof-specialty           Wife               Black    0             0   \n",
      "5     Exec-managerial           Wife               White    0             0   \n",
      "6       Other-service  Not-in-family               Black    0             0   \n",
      "7     Exec-managerial        Husband               White    1             0   \n",
      "8      Prof-specialty  Not-in-family               White    0         14084   \n",
      "9     Exec-managerial        Husband               White    1          5178   \n",
      "10    Exec-managerial        Husband               Black    1             0   \n",
      "11     Prof-specialty        Husband  Asian-Pac-Islander    1             0   \n",
      "12       Adm-clerical      Own-child               White    0             0   \n",
      "13              Sales  Not-in-family               Black    1             0   \n",
      "14   Transport-moving        Husband  Amer-Indian-Eskimo    1             0   \n",
      "\n",
      "    capital-loss  hours-per-week native-country  class  \n",
      "0              0              40  United-States  <=50K  \n",
      "1              0              13  United-States  <=50K  \n",
      "2              0              40  United-States  <=50K  \n",
      "3              0              40  United-States  <=50K  \n",
      "4              0              40           Cuba  <=50K  \n",
      "5              0              40  United-States  <=50K  \n",
      "6              0              16        Jamaica  <=50K  \n",
      "7              0              45  United-States   >50K  \n",
      "8              0              50  United-States   >50K  \n",
      "9              0              40  United-States   >50K  \n",
      "10             0              80  United-States   >50K  \n",
      "11             0              40          India   >50K  \n",
      "12             0              30  United-States  <=50K  \n",
      "13             0              50  United-States  <=50K  \n",
      "14             0              45         Mexico  <=50K  \n",
      "Save the Data to result1-2.csv\n",
      "Before Normalization:\n",
      "  capital-gain: Mean = 1092.0079, Std = 7406.3465\n",
      "  capital-loss: Mean = 88.3725, Std = 404.2984\n",
      "\n",
      "After Normalization:\n",
      "  capital-gain: Mean = -0.0000, Std = 1.0000\n",
      "  capital-loss: Mean = 0.0000, Std = 1.0000\n",
      "\n",
      "The last 15 records of Target Columns):\n",
      "       age  workclass  fnlwgt  education  education-num      marital-status  \\\n",
      "30147   37          2  198216          7             12            Divorced   \n",
      "30148   43          2  260761         11              9  Married-civ-spouse   \n",
      "30149   65          4   99359         14             15       Never-married   \n",
      "30150   43          5  255835         15             10            Divorced   \n",
      "30151   43          4   27242         15             10  Married-civ-spouse   \n",
      "30152   32          2   34066          0              6  Married-civ-spouse   \n",
      "30153   43          2   84661          8             11  Married-civ-spouse   \n",
      "30154   32          2  116138         12             14       Never-married   \n",
      "30155   53          2  321865         12             14  Married-civ-spouse   \n",
      "30156   22          2  310152         15             10       Never-married   \n",
      "30157   27          2  257302          7             12  Married-civ-spouse   \n",
      "30158   40          2  154374         11              9  Married-civ-spouse   \n",
      "30159   58          2  151910         11              9             Widowed   \n",
      "30160   22          2  201490         11              9       Never-married   \n",
      "30161   52          3  287927         11              9  Married-civ-spouse   \n",
      "\n",
      "              occupation    relationship                race  sex  \\\n",
      "30147       Tech-support   Not-in-family               White    0   \n",
      "30148  Machine-op-inspct         Husband               White    1   \n",
      "30149     Prof-specialty   Not-in-family               White    1   \n",
      "30150       Adm-clerical  Other-relative               White    0   \n",
      "30151       Craft-repair         Husband               White    1   \n",
      "30152  Handlers-cleaners         Husband  Amer-Indian-Eskimo    1   \n",
      "30153              Sales         Husband               White    1   \n",
      "30154       Tech-support   Not-in-family  Asian-Pac-Islander    1   \n",
      "30155    Exec-managerial         Husband               White    1   \n",
      "30156    Protective-serv   Not-in-family               White    1   \n",
      "30157       Tech-support            Wife               White    0   \n",
      "30158  Machine-op-inspct         Husband               White    1   \n",
      "30159       Adm-clerical       Unmarried               White    0   \n",
      "30160       Adm-clerical       Own-child               White    1   \n",
      "30161    Exec-managerial            Wife               White    0   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week native-country  class  \n",
      "30147     -0.147445     -0.218586              40  United-States  <=50K  \n",
      "30148     -0.147445     -0.218586              40         Mexico  <=50K  \n",
      "30149     -0.000811     -0.218586              60  United-States  <=50K  \n",
      "30150     -0.147445     -0.218586              40  United-States  <=50K  \n",
      "30151     -0.147445     -0.218586              50  United-States  <=50K  \n",
      "30152     -0.147445     -0.218586              40  United-States  <=50K  \n",
      "30153     -0.147445     -0.218586              45  United-States  <=50K  \n",
      "30154     -0.147445     -0.218586              11         Taiwan  <=50K  \n",
      "30155     -0.147445     -0.218586              40  United-States   >50K  \n",
      "30156     -0.147445     -0.218586              40  United-States  <=50K  \n",
      "30157     -0.147445     -0.218586              38  United-States  <=50K  \n",
      "30158     -0.147445     -0.218586              40  United-States   >50K  \n",
      "30159     -0.147445     -0.218586              40  United-States  <=50K  \n",
      "30160     -0.147445     -0.218586              20  United-States  <=50K  \n",
      "30161      1.881120     -0.218586              40  United-States   >50K  \n",
      "Save the Data to result1-3.csv\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
